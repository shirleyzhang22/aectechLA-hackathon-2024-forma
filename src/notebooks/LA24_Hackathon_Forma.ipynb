{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_ImLlAI6qZB"
      },
      "source": [
        "# Building a Chatbot\n",
        "## Part III: Building a chatbot UI\n",
        "Part I and II of exercise 4 taught us the mechanics of instructing the chatbot to answer user queries based on a custom databse that we define.\n",
        "\n",
        "An important part of any machine learning project is how you share it with other people. We spent all our time executing code snippets in this workshop. For our final notebook, we will look at how [Streamlit](https://streamlit.io/) can help us build a good looking user interface for our chatbot. As expected, we need to bring the modules that we created in parts I and II and organize them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF3q72rbIMjG"
      },
      "source": [
        "##Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoPsaglfJqNA"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install rank_bm25 pypdf2 tiktoken openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m-MW-BSIY9I"
      },
      "source": [
        "## Streamlit\n",
        "Streamlit requires all your python script inside a py file. The first line is a magic command that will write all the instructions we have had before into a single `chatbot.py` file. Let's quickly review the code together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NL6iOjFCXdXi",
        "outputId": "12317027-5ed7-4de8-f331-34d2d23f9aca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting chatbot.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile chatbot.py\n",
        "# load libraries\n",
        "import time\n",
        "import streamlit as st\n",
        "import pickle\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "\n",
        "# \"\"\"\n",
        "#   ____  _               _\n",
        "#  / ___|| |_ ___ _ __   / |\n",
        "#  \\___ \\| __/ _ \\ '_ \\  | |\n",
        "#   ___) | ||  __/ |_) | | |\n",
        "#  |____/ \\__\\___| .__/  |_|\n",
        "#                |_|\n",
        "# We define functions that load processed data and models into cache using streamlit's caching mechanism.\n",
        "# The cache command make the streamlit app faster and more responsive.\n",
        "# \"\"\"\n",
        "# define functions for chat gpt\n",
        "\n",
        "# POPULATE THESE PARAMETERS BEFORE RUNNING\n",
        "#API_KEY = \n",
        "#ASSISTANT_ID = \n",
        "#THREAD_ID =\n",
        "\n",
        "#access_code = \n",
        "#project_id = \n",
        "\n",
        "#these are all the fucntions for Custom GPT\n",
        "BASE_URL = \"https://api.openai.com/v1\"\n",
        "HEADERS = {\n",
        "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"OpenAI-Beta\": \"assistants=v2\"\n",
        "}\n",
        "\n",
        "def add_message(thread_id, content):\n",
        "    message_data = {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": content\n",
        "    }\n",
        "    requests.post(\n",
        "        f\"{BASE_URL}/threads/{thread_id}/messages\",\n",
        "        headers=HEADERS,\n",
        "        json=message_data\n",
        "    )\n",
        "\n",
        "def run_assistant(thread_id, assistant_id):\n",
        "    run_data = {\"assistant_id\": assistant_id}\n",
        "    response = requests.post(\n",
        "        f\"{BASE_URL}/threads/{thread_id}/runs\",\n",
        "        headers=HEADERS,\n",
        "        json=run_data\n",
        "    )\n",
        "    return response.json()['id']\n",
        "\n",
        "def wait_for_run_completion(thread_id, run_id):\n",
        "    while True:\n",
        "        response = requests.get(\n",
        "            f\"{BASE_URL}/threads/{thread_id}/runs/{run_id}\",\n",
        "            headers=HEADERS\n",
        "        )\n",
        "        status = response.json()['status']\n",
        "        if status == 'completed':\n",
        "            break\n",
        "        time.sleep(0.5)  # Poll every 0.5 seconds\n",
        "        # return response\n",
        "\n",
        "\n",
        "def get_assistant_reply(thread_id):\n",
        "    response = requests.get(\n",
        "        f\"{BASE_URL}/threads/{thread_id}/messages\",\n",
        "        headers=HEADERS\n",
        "    )\n",
        "    return response.json()['data'][0]['content'][0]['text']['value']\n",
        "\n",
        "\n",
        "def get_completion_from_messages(messages):\n",
        "    \"\"\"This function handles calls to the openai api and returns the response from the chatgpt model\"\"\"\n",
        "    add_message(THREAD_ID, messages)\n",
        "    run_id = run_assistant(THREAD_ID, ASSISTANT_ID)\n",
        "    wait_for_run_completion(THREAD_ID, run_id)\n",
        "    reply = get_assistant_reply(THREAD_ID)\n",
        "    return reply\n",
        "\n",
        "\n",
        "#these are all the functions for getting data from Forma\n",
        "def get_proposals(access_code):\n",
        "    url = f\"https://developer.api.autodesk.com/forma/proposal/v1alpha/proposals?authcontext={project_id}&limit=100\"\n",
        "    payload = {}\n",
        "    headers = {\n",
        "    'Authorization': f'Bearer {access_code}'\n",
        "    }\n",
        "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
        "    return response.json()\n",
        "\n",
        "def get_elements(proposals, access_code):\n",
        "    master_dict = {}\n",
        "    proposal_count = 1\n",
        "    for proposal in proposals[\"results\"]:\n",
        "        for building_index in range(len(proposal[\"children\"])):\n",
        "            if building_index != 0:\n",
        "                continue\n",
        "            else:\n",
        "                building_urn = proposal[\"children\"][building_index][\"urn\"]\n",
        "                # print(building_urn)\n",
        "                url = f\"https://developer.api.autodesk.com/forma/element-service/v1alpha/elements/{building_urn}?authcontext={project_id}\"\n",
        "\n",
        "                payload = {}\n",
        "                headers = {\n",
        "                'Authorization': f'Bearer {access_code}'\n",
        "                }\n",
        "                response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
        "                key = f\"proposal {proposal_count}\"\n",
        "                master_dict[key] = response.json()\n",
        "        proposal_count += 1\n",
        "\n",
        "    return master_dict\n",
        "\n",
        "\n",
        "# ref: https://docs.streamlit.io/knowledge-base/tutorials/build-conversational-apps\n",
        "st.title(\"Forma Chatbot\")\n",
        "\n",
        "if st.button('stream data'):\n",
        "  proposals = get_proposals(access_code)\n",
        "  data_input = get_elements(proposals, access_code)\n",
        "  st.write(data_input)\n",
        "\n",
        "  add_message(THREAD_ID, f\"{data_input}\")\n",
        "  run_id = run_assistant(THREAD_ID, ASSISTANT_ID)\n",
        "  wait_for_run_completion(THREAD_ID, run_id)\n",
        "  reply = get_assistant_reply(THREAD_ID)\n",
        "\n",
        "  st.write(reply)\n",
        "\n",
        "\n",
        "\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "    st.session_state.chat_hist = []\n",
        "\n",
        "for message in st.session_state.chat_hist:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "\n",
        "if prompt := st.chat_input(\"What is up?\"):\n",
        "    llm_prompt = prompt\n",
        "\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": llm_prompt})\n",
        "    st.session_state.chat_hist.append({\"role\": \"user\", \"content\": llm_prompt})\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(prompt)\n",
        "\n",
        "    with st.chat_message(\"assistant\"): # addd an avatar: ,avatar=\"TT_icon.png\"\n",
        "            message_placeholder = st.empty()\n",
        "            full_response = \"\"\n",
        "            stream = get_completion_from_messages(llm_prompt)\n",
        "            full_response = st.write(stream)\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": stream})\n",
        "    st.session_state.chat_hist.append({'role':'assistant', 'content':stream})\n",
        "\n",
        "# print references:\n",
        "# add a collapsible section to show reference documents\n",
        "# if len(st.session_state.chat_hist)>0:\n",
        "#     with st.expander(\"References\"):\n",
        "#         st.markdown(\"Reference documents:\")\n",
        "#         for i,doc in enumerate(st.session_state.chat_hist[0]['ref_docs']):\n",
        "#             st.write(f\"Reference {i+1}\")\n",
        "#             st.write(\"-\"*20)\n",
        "#             st.write(doc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLZZW4YDI8nG"
      },
      "source": [
        "##Building a local server\n",
        "The following lines are required to run a streamlit app in google colab. If you run this notebook localy, you only need to open an Anaconda propmt and type:\n",
        "`streamlit run chatbot.py` while changing your directory (`cd`) to the path of chatbot.py."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k89oS1zaXh0D",
        "outputId": "b26514e1-4603-4540-b77a-81f6fb57db33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25h\n",
            "up to date, audited 23 packages in 807ms\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "2 \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m severity vulnerabilities\n",
            "\n",
            "To address all issues (including breaking changes), run:\n",
            "  npm audit fix --force\n",
            "\n",
            "Run `npm audit` for details.\n"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit\n",
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDINpCDn3xo_"
      },
      "outputs": [],
      "source": [
        "!streamlit run chatbot.py &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8aKoVcJJmSS"
      },
      "source": [
        "This step is also needed because we are running the app on google colab. Please copy the endpoint ip and use it after clicking on the generated url."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUzO0pu64Jlb",
        "outputId": "c81dc39f-866a-4169-b338-caa42736cb91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Password/Enpoint IP for localtunnel is: 34.75.86.74\n"
          ]
        }
      ],
      "source": [
        "import urllib\n",
        "print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-obXLxl6XXa"
      },
      "source": [
        "Make sure secret_workshop.txt is uploaded to the files section of colab before running the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqylp_kk4N8a",
        "outputId": "7df49a43-e967-4586-d0c4-9076d3160397"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "your url is: https://yellow-otters-give.loca.lt\n"
          ]
        }
      ],
      "source": [
        "!npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCS_sQGcV9gm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
